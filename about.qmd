---
title: "About"
---

<!-- ## Research Orientation: *[WIP]*
Large blob of Compute with a-lot of data will always win but it still remains data-inefficient and lacks generalization thus can't be accounted for intelligence. -->

<!-- Reasoning with LLMs seems hard, because of their lack of generalization and ability to understand the underlying abstraction of the world. Obviously we have witnessed some of what we can call a reasoning behavior from LLMs agents distilled from large pre-training and further improved with RL for reward maximization. -->
<!-- that are now looking into another scaling direction of test-time-compute,  -->

